{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f4dd9f8f370>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os, os.path\n",
    "import copy\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import interp\n",
    "plt.ion()\n",
    "\n",
    "#Code adapted from: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donor1\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 20\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "nc = 3\n",
    "optimizer = \"SGD\" #or Adam or RMSprop\n",
    "imgSize = 224\n",
    "\n",
    "data_dir = './github/pictures'\n",
    "\n",
    "for x in os.listdir(data_dir):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torchvision.models.densenet161(weights=True) #https://pytorch.org/hub/pytorch_vision_densenet/\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, num_classes) #initialize and reshape densenet network\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#Load just the state_dict from the trained model\n",
    "model.load_state_dict(torch.load('./state_dict_densenet_classifier1.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a custom Dataset\n",
    "\n",
    "#Custom dataset to get image path https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "testdata_transforms = {\n",
    "    x: transforms.Compose([\n",
    "        transforms.CenterCrop(imgSize),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5894, 0.5352, 0.5669], [0.0749, 0.0701, 0.0634]) #mean and sd of training images\n",
    "    ])\n",
    "    for x in os.listdir(data_dir)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'donor1': 23}\n"
     ]
    }
   ],
   "source": [
    "image_datasets = {x: ImageFolderWithPaths(os.path.join(data_dir, x), testdata_transforms[x]) \n",
    "                  for x in os.listdir(data_dir)}\n",
    "\n",
    "testdataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "              for x in os.listdir(data_dir)}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in os.listdir(data_dir)}\n",
    "print(dataset_sizes)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donor1\n",
      "Predicted MBS: 2.6956521739130435\n",
      "True MBS: 2.260869565217391\n"
     ]
    }
   ],
   "source": [
    "#Predictions saved in CSV files\n",
    "preds = np.zeros(shape = (0,3))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x in os.listdir(data_dir):\n",
    "        print(str(x))\n",
    "        preds = np.zeros((0,3))\n",
    "        for images, labels, paths in testdataloaders[x]:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds_batch = np.concatenate((np.array(paths).reshape(len(paths),1),\n",
    "                                          np.array(predicted).reshape(len(predicted),1),\n",
    "                                          np.array(labels).reshape(len(labels),1)), axis = 1)\n",
    "            preds = np.concatenate((preds, preds_batch), axis = 0)\n",
    "        np.savetxt('./results/' + str(x) + '.csv', preds, delimiter=',', header = \"filepath, predicted, truth\", fmt='%s')\n",
    "        print(\"Predicted MBS:\", np.mean(preds[:,1].astype(float))*2)\n",
    "        print(\"True MBS:\", np.mean(preds[:,2].astype(float))*2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
